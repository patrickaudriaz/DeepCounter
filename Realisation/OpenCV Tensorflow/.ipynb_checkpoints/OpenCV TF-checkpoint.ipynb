{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import dlib\n",
    "\n",
    "os.sys.path\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamIP = \"http://160.98.31.178:8080/stream/video.mjpeg\"\n",
    "\n",
    "inputFile = \"../dataset/townlow.mp4\"\n",
    "\n",
    "# minimum probability to filter weak detections\n",
    "minConfidence = 0.5\n",
    "\n",
    "skipFrames = 5\n",
    "\n",
    "global totalIn\n",
    "global totalOut\n",
    "\n",
    "FPSUpdate = 20\n",
    "liveFPS = 0\n",
    "\n",
    "# Width of network's input image\n",
    "inputWidth = 300\n",
    "# Height of network's input image\n",
    "inputHeight = 300\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "pbFile = \"tf/ssd_inception_frozen_inference_graph.pb\"\n",
    "pbtxtFile = \"tf/ssd_inception_v2_coco_2017_11_17.pbtxt\"\n",
    "\n",
    "modelName = \"SSD Inception V2\"\n",
    "\n",
    "# initialize a list of colors to represent each possible class label\n",
    "np.random.seed(3232)\n",
    "colors = np.random.randint(0, 255, size=(1000, 3),\n",
    "                           dtype=\"uint8\")\n",
    "\n",
    "\n",
    "status = \"off\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 720\n"
     ]
    }
   ],
   "source": [
    "vs = cv2.VideoCapture(streamIP)\n",
    "\n",
    "# vs = cv2.VideoCapture(inputFile)\n",
    "\n",
    "H = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "W = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "print(W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model from disk...\n",
      "[INFO] ... done !\n"
     ]
    }
   ],
   "source": [
    "# Load the serialized caffe model from disk:\n",
    "print(\"[INFO] loading model from disk...\")\n",
    "\n",
    "# Give the configuration and weight files for the model and load the \n",
    "# network using them.\n",
    "net = cv2.dnn.readNetFromTensorflow(pbFile, pbtxtFile)\n",
    "\n",
    "print(\"[INFO] ... done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to draw bounding box on the detected object with class name and precision\n",
    "def drawBoundingBox(frame, box, centroid, color):\n",
    "    (startX, startY, endX, endY) = box\n",
    "\n",
    "    # draw a red rectangle around detected objects\n",
    "    cv2.rectangle(frame, (int(startX), int(startY)), (int(\n",
    "        endX), int(endY)), color, thickness=2)\n",
    "\n",
    "#     cv2.putText(frame, \"{:.3f}\".format(confidence), (int(startX), int(startY - 5)), font,\n",
    "#                 0.5, (0, 128, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "#     cv2.circle(frame, (int(centroid[0]), int(centroid[1])), 4, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "def computeCentroid(box):\n",
    "    (startX, startY, endX, endY) = box\n",
    "    return np.array([startX + ((endX - startX)/2), startY + ((endY - startY)/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class TrackableObject:\n",
    "    def __init__(self, objectID, centroid):\n",
    "        # store the object ID, then initialize a list of centroids\n",
    "        # using the current centroid\n",
    "        self.objectID = objectID\n",
    "        self.centroids = [centroid]\n",
    "\n",
    "        # initialize a boolean used to indicate if the object has\n",
    "        # already been counted or not\n",
    "        self.counted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=30, maxDistance=30):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "        # store the maximum distance between centroids to associate\n",
    "        # an object -- if the distance is larger than this maximum\n",
    "        # distance we'll start to mark the object as \"disappeared\"\n",
    "        self.maxDistance = maxDistance\n",
    "\n",
    "    def register(self, centroid):\n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # if the distance between centroids is greater than\n",
    "                # the maximum distance, do not associate the two\n",
    "                # centroids to the same object\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "\n",
    "        # return the set of trackable objects\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame, detections):\n",
    "    # loop over the detections\n",
    "    for detection in detections[0, 0, :, :]:\n",
    "        # extract the confidence (i.e., probability) associated\n",
    "        # with the prediction\n",
    "        confidence = float(detection[2])\n",
    "\n",
    "        if (confidence > minConfidence):\n",
    "            classID = detection[1]\n",
    "\n",
    "            if(classID == 1):\n",
    "                left = detection[3] * W\n",
    "                top = detection[4] * H\n",
    "                right = detection[5] * W\n",
    "                bottom = detection[6] * H\n",
    "\n",
    "                box = [left, top, right, bottom]\n",
    "\n",
    "                # construct a dlib rectangle object from the bounding\n",
    "                # box coordinates and then start the dlib correlation\n",
    "                # tracker\n",
    "                tracker = dlib.correlation_tracker()\n",
    "                rect = dlib.rectangle(int(left), int(\n",
    "                    top), int(right), int(bottom))\n",
    "\n",
    "                tracker.start_track(frame, rect)\n",
    "\n",
    "                trackers.append(tracker)\n",
    "\n",
    "                # rects.append(box)\n",
    "\n",
    "                centroid = computeCentroid(box)\n",
    "\n",
    "                drawBoundingBox(frame, box, centroid, color=(0, 0, 255))\n",
    "\n",
    "                cv2.putText(frame, status, (0, 115), font,\n",
    "                            0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def track(frame, trackers):\n",
    "    for tracker in trackers:\n",
    "        status = \"Tracking\"\n",
    "        # update the tracker and grab the position of the tracked\n",
    "        # object\n",
    "        tracker.update(frame)\n",
    "\n",
    "        pos = tracker.get_position()\n",
    "\n",
    "        # unpack the position object\n",
    "        left = int(pos.left())\n",
    "        top = int(pos.top())\n",
    "        right = int(pos.right())\n",
    "        bottom = int(pos.bottom())\n",
    "\n",
    "        box = [left, top, right, bottom]\n",
    "\n",
    "        rects.append(box)\n",
    "\n",
    "        centroid = computeCentroid(box)\n",
    "\n",
    "        drawBoundingBox(frame, box, centroid, color=(0, 128, 255))\n",
    "\n",
    "        cv2.putText(frame, status, (0, 95), font,\n",
    "                    0.5, (0, 255, 0), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting(objects):\n",
    "    \n",
    "    global totalIn\n",
    "    global totalOut\n",
    "    \n",
    "    # loop over the tracked objects\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # check to see if a trackable object exists for the current\n",
    "        # object ID\n",
    "        to = trackableObjects.get(objectID, None)\n",
    "\n",
    "        # if there is no existing trackable object, create one\n",
    "        if to is None:\n",
    "            to = TrackableObject(objectID, centroid)\n",
    "\n",
    "        # otherwise, there is a trackable object so we can utilize it\n",
    "        # to determine direction\n",
    "        else:\n",
    "            # the difference between the y-coordinate of the *current*\n",
    "            # centroid and the mean of *previous* centroids will tell\n",
    "            # us in which direction the object is moving (negative for\n",
    "            # 'up' and positive for 'down')\n",
    "            y = [c[1] for c in to.centroids]\n",
    "            direction = centroid[1] - np.mean(y)\n",
    "            to.centroids.append(centroid)\n",
    "            \n",
    "            # check to see if the object has been counted or not\n",
    "            if not to.counted:\n",
    "                # if the direction is negative (indicating the object\n",
    "                # is moving up) AND the centroid is above the center\n",
    "                # line, count the object\n",
    "                if direction < 0 and centroid[1] < H // 2:\n",
    "                    totalOut += 1\n",
    "                    to.counted = True\n",
    "\n",
    "                # if the direction is positive (indicating the object\n",
    "                # is moving down) AND the centroid is below the\n",
    "                # center line, count the object\n",
    "                elif direction > 0 and centroid[1] > H // 2:\n",
    "                    totalIn += 1\n",
    "                    to.counted = True\n",
    "\n",
    "        # store the trackable object in our dictionary\n",
    "        trackableObjects[objectID] = to\n",
    "\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        color = [int(c) for c in colors[objectID]]\n",
    "\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, color, -1)\n",
    "        cv2.putText(frame, \"ID : \" + str(objectID), (centroid[0], centroid[1]+20), font,\n",
    "                    0.6, color, 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each frames\n",
    "\n",
    "1. load coco names\n",
    "- load YOLO config and weights\n",
    "- load input video\n",
    "- use OpenCV dnn module (readNetFromDarknet)\n",
    "- create __blob__ (img preprocessing) (https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] approx. FPS: 29.75\n",
      "OUT :  6\n",
      "IN :  0\n"
     ]
    }
   ],
   "source": [
    "# initialize t dlib correlation tracker and CentroidTracker\n",
    "ct = CentroidTracker(maxDisappeared=50, maxDistance=100)\n",
    "\n",
    "trackers = []\n",
    "trackableObjects = {}\n",
    "\n",
    "totalFrames = 0\n",
    "\n",
    "totalOut = 0\n",
    "totalIn = 0\n",
    "\n",
    "# start the frames per second throughput estimator\n",
    "fps = FPS().start()\n",
    "totalFPS = FPS().start()\n",
    "\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "    # read the next frame from the file\n",
    "    (grabbed, frame) = vs.read()\n",
    "\n",
    "    # if the frame was not grabbed, then we have reached the end\n",
    "    # of the stream\n",
    "    if not grabbed:\n",
    "        print(\"Done processing !!!\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "#     frame = imutils.resize(frameRaw, width=500)\n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "#     frame = cv2.cvtColor(frameRaw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    rects = []\n",
    "\n",
    "    # process only every n frames to improve performances\n",
    "    # strat dlib correlation tracker on detections\n",
    "    if totalFrames % skipFrames == 0:\n",
    "        trackers = []\n",
    "        status = \"Detecting\"\n",
    "\n",
    "        # Create the blob with a size of (416, 416), swap red and blue channels\n",
    "        # and also a scale factor of 1/255 = 0,003921568627451:\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            frame, size=(400, 400), swapRB=True, crop=False)\n",
    "\n",
    "        # Feed the input blob to the network, perform inference and get the output:\n",
    "        # Set the input for the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        start = time.time()\n",
    "        detections = net.forward()\n",
    "        end = time.time()\n",
    "        \n",
    "        #############################\n",
    "        # loop over the detections\n",
    "        for detection in detections[0, 0, :, :]:\n",
    "            # extract the confidence (i.e., probability) associated\n",
    "            # with the prediction\n",
    "            confidence = float(detection[2])\n",
    "\n",
    "            if (confidence > minConfidence):\n",
    "                classID = detection[1]\n",
    "\n",
    "                if(classID == 1):\n",
    "                    left = detection[3] * W\n",
    "                    top = detection[4] * H\n",
    "                    right = detection[5] * W\n",
    "                    bottom = detection[6] * H\n",
    "\n",
    "                    box = [left, top, right, bottom]\n",
    "\n",
    "                    # construct a dlib rectangle object from the bounding\n",
    "                    # box coordinates and then start the dlib correlation\n",
    "                    # tracker\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    rect = dlib.rectangle(int(left), int(\n",
    "                        top), int(right), int(bottom))\n",
    "\n",
    "                    tracker.start_track(frame, rect)\n",
    "\n",
    "                    trackers.append(tracker)\n",
    "                    \n",
    "                    rects.append(box)\n",
    "\n",
    "                    # rects.append(box)\n",
    "\n",
    "                    centroid = computeCentroid(box)\n",
    "\n",
    "                    drawBoundingBox(frame, box, centroid, color=(0, 0, 255))\n",
    "\n",
    "                    cv2.putText(frame, status, (0, 115), font,\n",
    "                                0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        #############################\n",
    "        for tracker in trackers:\n",
    "            status = \"Tracking\"\n",
    "            # update the tracker and grab the position of the tracked\n",
    "            # object\n",
    "            tracker.update(frame)\n",
    "\n",
    "            pos = tracker.get_position()\n",
    "\n",
    "            # unpack the position object\n",
    "            left = int(pos.left())\n",
    "            top = int(pos.top())\n",
    "            right = int(pos.right())\n",
    "            bottom = int(pos.bottom())\n",
    "\n",
    "            box = [left, top, right, bottom]\n",
    "\n",
    "            rects.append(box)\n",
    "\n",
    "            centroid = computeCentroid(box)\n",
    "\n",
    "            drawBoundingBox(frame, box, centroid, color=(0, 128, 255))\n",
    "\n",
    "            cv2.putText(frame, status, (0, 95), font,\n",
    "                        0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # draw a horizontal line in the center of the frame -- once an\n",
    "    # object crosses this line we will determine whether they were\n",
    "    # moving 'up' or 'down'\n",
    "    cv2.line(frame, (0, H // 2), (W, H // 2), (0, 255, 255), 1)\n",
    "\n",
    "    # use the centroid tracker to associate the (1) old object\n",
    "    # centroids with (2) the newly computed object centroids\n",
    "    objects = ct.update(rects)\n",
    "    \n",
    "    ##############################\n",
    "    # loop over the tracked objects\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # check to see if a trackable object exists for the current\n",
    "        # object ID\n",
    "        to = trackableObjects.get(objectID, None)\n",
    "\n",
    "        # if there is no existing trackable object, create one\n",
    "        if to is None:\n",
    "            to = TrackableObject(objectID, centroid)\n",
    "\n",
    "        # otherwise, there is a trackable object so we can utilize it\n",
    "        # to determine direction\n",
    "        else:\n",
    "            # the difference between the y-coordinate of the *current*\n",
    "            # centroid and the mean of *previous* centroids will tell\n",
    "            # us in which direction the object is moving (negative for\n",
    "            # 'up' and positive for 'down')\n",
    "            y = [c[1] for c in to.centroids]\n",
    "            direction = centroid[1] - np.mean(y)\n",
    "            to.centroids.append(centroid)\n",
    "                \n",
    "            # check to see if the object has been counted or not\n",
    "            if not to.counted:\n",
    "                # if the direction is negative (indicating the object\n",
    "                # is moving up) AND the centroid is above the center\n",
    "                # line, count the object\n",
    "                if direction < 0 and centroid[1] < H // 2:\n",
    "                    totalOut += 1\n",
    "                    to.counted = True\n",
    "\n",
    "                # if the direction is positive (indicating the object\n",
    "                # is moving down) AND the centroid is below the\n",
    "                # center line, count the object\n",
    "                elif direction > 0 and centroid[1] > H // 2:\n",
    "                    totalIn += 1\n",
    "                    to.counted = True\n",
    "\n",
    "        # store the trackable object in our dictionary\n",
    "        trackableObjects[objectID] = to\n",
    "\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        color = [int(c) for c in colors[objectID]]\n",
    "\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, color, -1)\n",
    "        cv2.putText(frame, \"ID : \" + str(objectID), (centroid[0], centroid[1]+20), font,\n",
    "                    0.6, color, 1, cv2.LINE_AA)\n",
    "\n",
    "    # construct a tuple of information we will be displaying on the\n",
    "    # frame\n",
    "    info = [\n",
    "        (\"Out\", totalOut),\n",
    "        (\"In\", totalIn)\n",
    "    ]\n",
    "\n",
    "    # loop over the info tuples and draw them on our frame\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "                    font, 0.6, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # increment the total number of frames processed thus far and\n",
    "    # then update the FPS counter\n",
    "    totalFrames = totalFrames + 1\n",
    "    fps.update()\n",
    "\n",
    "    # process only every n frames to improve performances\n",
    "    if totalFrames % FPSUpdate == 0:\n",
    "        fps.stop()\n",
    "        liveFPS = fps.fps()\n",
    "        # start the frames per second throughput estimator\n",
    "        fps = FPS().start()\n",
    "\n",
    "    cv2.putText(frame, \"Model : \" + modelName, (0, 15),\n",
    "                font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"Resolution : \" + str(W) + \"x\" + str(H),\n",
    "                (0, 35), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"FPS: {:.1f}\".format(liveFPS),\n",
    "                (0, 55), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"Detection : {:.2f} sec\".format(\n",
    "        end - start), (0, 75), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    totalFPS.update()\n",
    "\n",
    "    cv2.imshow('RPI', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "totalFPS.stop()\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(totalFPS.fps()))\n",
    "print(\"OUT : \", totalOut)\n",
    "print(\"IN : \", totalIn)\n",
    "\n",
    "\n",
    "# release the file pointers\n",
    "# writer.release()\n",
    "vs.release()\n",
    "\n",
    "# close any open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# constants used to push new measure in BBData\n",
    "url = 'https://bbdata.daplab.ch/input/measures'\n",
    "headers = {'content-type': 'application/json', 'accept': 'application/json'}\n",
    "\n",
    "def push_to_bbdata(object_id, object_token, value):\n",
    "    # get current timestamp and format to ISO\n",
    "    now = datetime.datetime.utcnow().replace(microsecond=0).isoformat()\n",
    "\n",
    "    # form the payload with parameters\n",
    "    payload = {\"objectId\": object_id, \"token\": object_token, \"timestamp\": now, \"value\": value}\n",
    "\n",
    "    response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "    # 0 if success and -1 if there is an error\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success\")\n",
    "        print(response.json())\n",
    "        return 0\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "{'objectId': 13320, 'timestamp': '2019-06-26T15:07:55.000', 'value': '1000', 'owner': 46}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_to_bbdata(13320, \"164736f3f6be6c230214f46a4ccbab96\", 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
